
#  RISC-V Pipelined Processor with 2-Level Cache Controller

## üìå Overview

This project implements a **5-stage pipelined RISC-V processor** fully integrated with a **2-level cache hierarchy** to demonstrate real-world improvements in instruction throughput and memory latency reduction.

The entire design is written in **Verilog HDL**, synthesized, and tested using **Xilinx Vivado**.

---

## ‚öôÔ∏è Pipeline Architecture

- **Pipeline Stages**
  - **IF**: Instruction Fetch
  - **ID**: Instruction Decode
  - **EX**: Execute
  - **MEM**: Memory Access
  - **WB**: Write Back

- **Pipeline Registers** isolate each stage for instruction-level parallelism.

- **Hazard Detection Unit** automatically handles data hazards with stalls or forwarding.

- **Control Unit** generates control signals to coordinate pipeline flow.

---

## üóÇÔ∏è Cache Controller

- **2-Level Cache Hierarchy**
  - **L1 Cache**: Direct-mapped, fast single-cycle access for instructions and data.
  - **L2 Cache**: 4-way set-associative with **LRU (Least Recently Used)** replacement policy, providing better conflict miss handling than direct-mapped alone.

- **Write Strategy**
  - **Write-back**: Modified blocks write back to lower memory only on eviction.
  - **Write-no-allocate**: On a write miss, data is written directly to the next level or main memory without allocating a new cache block ‚Äî reduces unnecessary fills for poor-write-locality patterns.

This hierarchy balances **fast access (L1)** and **higher capacity (L2)** while minimizing main memory traffic.

---

## ‚ö° Performance Analysis

### ‚è±Ô∏è Clock Design

| Component | Period | Frequency |
|-----------------|---------|--------------|
| **Processor Clock** | 20‚ÄØns | 50‚ÄØMHz |
| **Cache Controller Clock** | 6‚ÄØns | ~167‚ÄØMHz |

- The processor clock is chosen to fit pipeline logic, hazard detection, and register access.
- The cache controller runs faster to complete tag comparisons and set indexing well within each processor cycle.

---

### üß© Cache & Memory Latencies (Cache Clock Cycles)

| Memory Level | Latency (cache clock cycles) | Latency (ns) | Approx. CPU clock cycles |
|----------------|-------------------------------|-----------------|-----------------------------|
| **L1 Cache** | 1 cycle | 6‚ÄØns | ~0.3 CPU cycles |
| **L2 Cache** | 3 cycles | 18‚ÄØns | ~0.9 CPU cycles |
| **Main Memory** | 10 cycles | 60‚ÄØns | ~3 CPU cycles |


---

## üìà CPI & Speedup Comparison

### üîç Scenario

- **Main Memory Latency**: 10 cycles of cache controller clock  
  ‚Üí At 6‚ÄØns per cache cycle ‚Üí 60‚ÄØns total.
  ‚Üí In CPU clock units (20‚ÄØns): `60‚ÄØns √∑ 20‚ÄØns = 3 CPU cycles`.

- **Hierarchy:**
  - **L1**: 1 CPU cycle
  - **L2**: 3 CPU cycles
  - **Main Memory**: ~3 CPU cycles

- **Typical Load/Store Fraction:** ~30% of instructions.

---

### ‚ö° CPI Estimates

| | Without Cache | With L1/L2 Cache |
|----------------|-----------------|---------------------|
| **Pipeline Ideal CPI** | ~1.0 | ~1.0 |
| **Practical CPI** | ~1.6 | ~1.03 |

**How it‚Äôs calculated:**

- **No Cache:**  
  Every load/store takes 3 CPU cycles (direct main memory access).  


**Estimates:**
- L1 Hit Rate: ~95%
- L2 covers ~50% of remaining misses ‚Üí only ~2.5% reach main memory
- Effective average memory latency:
